{"cells":[{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["ERROR: No matching packages\n"]}],"source":["pip cache purge"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["The system cannot find the file specified.\n"]}],"source":["pip install numpy<2.0.0 torch pandas scikit-learn tqdm ipykernel\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pandas in c:\\users\\laiba ahmad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.2.2)\n","Collecting numpy>=1.22.4; python_version < \"3.11\"\n","  Using cached numpy-2.0.0-cp39-cp39-win_amd64.whl (16.5 MB)\n","Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\laiba ahmad\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in c:\\users\\laiba ahmad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in c:\\users\\laiba ahmad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2024.1)\n","Requirement already satisfied: six>=1.5 in c:\\users\\laiba ahmad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","Installing collected packages: numpy\n","Successfully installed numpy-2.0.0\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["  WARNING: The scripts f2py.exe and numpy-config.exe are installed in 'c:\\Users\\Laiba Ahmad\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n","  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n","WARNING: You are using pip version 20.2.3; however, version 24.1 is available.\n","You should consider upgrading via the 'c:\\Users\\Laiba Ahmad\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"]}],"source":["pip install pandas"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: scikit-learn in c:\\users\\laiba ahmad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.5.0)Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: You are using pip version 20.2.3; however, version 24.1 is available.\n","You should consider upgrading via the 'c:\\Users\\Laiba Ahmad\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"]},{"name":"stdout","output_type":"stream","text":["\n","Requirement already satisfied: numpy>=1.19.5 in c:\\users\\laiba ahmad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (2.0.0)\n","Requirement already satisfied: joblib>=1.2.0 in c:\\users\\laiba ahmad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: scipy>=1.6.0 in c:\\users\\laiba ahmad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (1.13.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\laiba ahmad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (3.5.0)\n"]}],"source":["pip install scikit-learn"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tqdm in c:\\users\\laiba ahmad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (4.66.4)\n","Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\laiba ahmad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm) (0.4.6)\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: You are using pip version 20.2.3; however, version 24.1 is available.\n","You should consider upgrading via the 'c:\\Users\\Laiba Ahmad\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"]}],"source":["pip install tqdm"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["The system cannot find the file specified.\n"]}],"source":["pip install numpy<2"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torch in c:\\users\\laiba ahmad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.3.1)Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: You are using pip version 20.2.3; however, version 24.1 is available.\n","You should consider upgrading via the 'c:\\Users\\Laiba Ahmad\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"]},{"name":"stdout","output_type":"stream","text":["\n","Requirement already satisfied: jinja2 in c:\\users\\laiba ahmad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (3.1.4)\n","Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1; platform_system == \"Windows\" in c:\\users\\laiba ahmad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (2021.4.0)\n","Requirement already satisfied: filelock in c:\\users\\laiba ahmad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (3.15.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\laiba ahmad\\appdata\\roaming\\python\\python39\\site-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in c:\\users\\laiba ahmad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (1.12.1)\n","Requirement already satisfied: networkx in c:\\users\\laiba ahmad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (3.2.1)\n","Requirement already satisfied: fsspec in c:\\users\\laiba ahmad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (2024.6.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\laiba ahmad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: tbb==2021.* in c:\\users\\laiba ahmad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1; platform_system == \"Windows\"->torch) (2021.13.0)\n","Requirement already satisfied: intel-openmp==2021.* in c:\\users\\laiba ahmad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1; platform_system == \"Windows\"->torch) (2021.4.0)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in c:\\users\\laiba ahmad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sympy->torch) (1.3.0)\n"]}],"source":["pip install torch"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torch in c:\\users\\laiba ahmad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.3.1)Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: You are using pip version 20.2.3; however, version 24.1 is available.\n","You should consider upgrading via the 'c:\\Users\\Laiba Ahmad\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"]},{"name":"stdout","output_type":"stream","text":["\n","Requirement already satisfied: torchvision in c:\\users\\laiba ahmad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.18.1)\n","Requirement already satisfied: networkx in c:\\users\\laiba ahmad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (3.2.1)\n","Requirement already satisfied: filelock in c:\\users\\laiba ahmad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (3.15.4)\n","Requirement already satisfied: jinja2 in c:\\users\\laiba ahmad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (3.1.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\laiba ahmad\\appdata\\roaming\\python\\python39\\site-packages (from torch) (4.12.2)\n","Requirement already satisfied: fsspec in c:\\users\\laiba ahmad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (2024.6.0)\n","Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1; platform_system == \"Windows\" in c:\\users\\laiba ahmad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (2021.4.0)\n","Requirement already satisfied: sympy in c:\\users\\laiba ahmad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (1.12.1)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\laiba ahmad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchvision) (10.3.0)\n","Requirement already satisfied: numpy in c:\\users\\laiba ahmad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchvision) (1.26.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\laiba ahmad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: intel-openmp==2021.* in c:\\users\\laiba ahmad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1; platform_system == \"Windows\"->torch) (2021.4.0)\n","Requirement already satisfied: tbb==2021.* in c:\\users\\laiba ahmad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1; platform_system == \"Windows\"->torch) (2021.13.0)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in c:\\users\\laiba ahmad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sympy->torch) (1.3.0)\n"]}],"source":["pip install torch torchvision\n"]},{"cell_type":"code","execution_count":40,"metadata":{"executionInfo":{"elapsed":148,"status":"ok","timestamp":1624054305187,"user":{"displayName":"Armin Bazarjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWMh-oi0YJtI-yJdyLDSVztfUualX2xpx_lq-GGA=s64","userId":"09638783858940923330"},"user_tz":420},"id":"ag2kCPtZFBAH"},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from tqdm import tqdm\n","import numpy as np\n","# torch imports\n","import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision import transforms\n","from torch.utils.data import Dataset\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19477,"status":"ok","timestamp":1624052397587,"user":{"displayName":"Armin Bazarjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWMh-oi0YJtI-yJdyLDSVztfUualX2xpx_lq-GGA=s64","userId":"09638783858940923330"},"user_tz":420},"id":"VVbjazrSFgB2","outputId":"cce1ed1c-7ec8-4a03-9acd-c02332fa3f31"},"outputs":[{"data":{"text/plain":["\" # Run this once\\nfrom google.colab import drive\\ndrive.mount('/content/gdrive')\\n# You will have to modify this based on your Google Drive directory structure\\n%cd /content/gdrive/MyDrive/Colab Notebooks/RideStream/\\n!pwd \""]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\" # Run this once\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","# You will have to modify this based on your Google Drive directory structure\n","%cd /content/gdrive/MyDrive/Colab Notebooks/RideStream/\n","!pwd \"\"\""]},{"cell_type":"code","execution_count":42,"metadata":{"executionInfo":{"elapsed":230,"status":"ok","timestamp":1624052399780,"user":{"displayName":"Armin Bazarjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWMh-oi0YJtI-yJdyLDSVztfUualX2xpx_lq-GGA=s64","userId":"09638783858940923330"},"user_tz":420},"id":"UVr-wVukIkfA"},"outputs":[],"source":["class UTKDataset(Dataset):\n","    '''\n","        Inputs:\n","            dataFrame : Pandas dataFrame\n","            transform : The transform to apply to the dataset\n","    '''\n","    def __init__(self, dataFrame, transform=None):\n","        # read in the transforms\n","        self.transform = transform\n","        \n","        # Use the dataFrame to get the pixel values\n","        data_holder = dataFrame.pixels.apply(lambda x: np.array(x.split(\" \"),dtype=float))\n","        arr = np.stack(data_holder)\n","        arr = arr / 255.0\n","        arr = arr.astype('float32')\n","        arr = arr.reshape(arr.shape[0], 48, 48, 1)\n","        # reshape into 48x48x1\n","        self.data = arr\n","        \n","        # get the age, gender, and ethnicity label arrays\n","        self.age_label = np.array(dataFrame.bins[:])        # Note : Changed dataFrame.age to dataFrame.bins with most recent change\n","        self.gender_label = np.array(dataFrame.gender[:])\n","        self.eth_label = np.array(dataFrame.ethnicity[:])\n","    \n","    # override the length function\n","    def __len__(self):\n","        return len(self.data)\n","    \n","    # override the getitem function\n","    def __getitem__(self, index):\n","        # load the data at index and apply transform\n","        data = self.data[index]\n","        data = self.transform(data)\n","        \n","        # load the labels into a list and convert to tensors\n","        labels = torch.tensor((self.age_label[index], self.gender_label[index], self.eth_label[index]))\n","        \n","        # return data labels\n","        return data, labels"]},{"cell_type":"code","execution_count":43,"metadata":{"executionInfo":{"elapsed":239,"status":"ok","timestamp":1624052401669,"user":{"displayName":"Armin Bazarjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWMh-oi0YJtI-yJdyLDSVztfUualX2xpx_lq-GGA=s64","userId":"09638783858940923330"},"user_tz":420},"id":"cxkn0VdIIlQO"},"outputs":[],"source":["# High level feature extractor network (Adopted VGG type structure)\n","class highLevelNN(nn.Module):\n","    def __init__(self):\n","        super(highLevelNN, self).__init__()\n","        self.CNN = nn.Sequential(\n","            # first batch (32)\n","            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1),\n","            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n","            nn.ReLU(),\n","\n","            # second batch (64)\n","            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n","            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n","            nn.ReLU(),\n","\n","            # Third Batch (128)\n","            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n","            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n","            nn.ReLU(),\n","        )\n","\n","    def forward(self, x):\n","        out = self.CNN(x)\n","\n","        return out\n","\n","# Low level feature extraction module\n","class lowLevelNN(nn.Module):\n","    def __init__(self, num_out):\n","        super(lowLevelNN, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n","        self.conv2 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1)\n","        self.fc1 = nn.Linear(in_features=2048, out_features=256)\n","        self.fc2 = nn.Linear(in_features=256, out_features=128)\n","        self.fc3 = nn.Linear(in_features=128, out_features=64)\n","        self.fc4 = nn.Linear(in_features=64, out_features=num_out)\n","\n","    def forward(self, x):\n","        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=3, stride=2, padding=1))\n","        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=3, stride=2, padding=1))\n","        x = torch.flatten(x, start_dim=1)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = F.relu(self.fc3(x))\n","        x = self.fc4(x)\n","\n","        return x\n","\n","\n","class TridentNN(nn.Module):\n","    def __init__(self, num_age, num_gen, num_eth):\n","        super(TridentNN, self).__init__()\n","        # Construct the high level neural network\n","        self.CNN = highLevelNN()\n","        # Construct the low level neural networks\n","        self.ageNN = lowLevelNN(num_out=num_age)\n","        self.genNN = lowLevelNN(num_out=num_gen)\n","        self.ethNN = lowLevelNN(num_out=num_eth)\n","\n","    def forward(self, x):\n","        x = self.CNN(x)\n","        age = self.ageNN(x)\n","        gen = self.genNN(x)\n","        eth = self.ethNN(x)\n","\n","        return age, gen, eth"]},{"cell_type":"code","execution_count":44,"metadata":{"executionInfo":{"elapsed":190,"status":"ok","timestamp":1624054659108,"user":{"displayName":"Armin Bazarjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWMh-oi0YJtI-yJdyLDSVztfUualX2xpx_lq-GGA=s64","userId":"09638783858940923330"},"user_tz":420},"id":"S78Li3j0JeB8"},"outputs":[],"source":["'''\n","    Function to test the trained model\n","\n","    Inputs:\n","      - testloader : PyTorch DataLoader containing the test dataset\n","      - modle : Trained NeuralNetwork\n","    \n","    Outputs:\n","      - Prints out test accuracy for gender and ethnicity and loss for age\n","'''\n","def test(testloader, model):\n","  device = 'cuda' if torch.cuda.is_available() else 'cpu' \n","  size = len(testloader.dataset)\n","  # put the moel in evaluation mode so we aren't storing anything in the graph\n","  model.eval()\n","\n","  age_acc, gen_acc, eth_acc = 0, 0, 0\n","\n","  with torch.no_grad():\n","      for X, y in testloader:\n","          X = X.to(device)\n","          age, gen, eth = y[:,0].to(device), y[:,1].to(device), y[:,2].to(device)\n","          pred = model(X)\n","\n","          age_acc += (pred[0].argmax(1) == age).type(torch.float).sum().item()\n","          gen_acc += (pred[1].argmax(1) == gen).type(torch.float).sum().item()\n","          eth_acc += (pred[2].argmax(1) == eth).type(torch.float).sum().item()\n","\n","  age_acc /= size\n","  gen_acc /= size\n","  eth_acc /= size\n","\n","  print(f\"Age Accuracy : {age_acc*100}%,     Gender Accuracy : {gen_acc*100},    Ethnicity Accuracy : {eth_acc*100}\\n\")"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11082,"status":"ok","timestamp":1624053963605,"user":{"displayName":"Armin Bazarjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWMh-oi0YJtI-yJdyLDSVztfUualX2xpx_lq-GGA=s64","userId":"09638783858940923330"},"user_tz":420},"id":"r9QWQfreI_qW","outputId":"017215ff-675b-437b-c638-c4dcf72641be"},"outputs":[{"ename":"RuntimeError","evalue":"Numpy is not available","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[1;32mIn[46], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m testloader \u001b[38;5;241m=\u001b[39m DataLoader(test_set, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Sanity Check\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X, y \u001b[38;5;129;01min\u001b[39;00m trainloader:\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShape of training X: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShape of y: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[1;32mc:\\Users\\Laiba Ahmad\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[1;32mc:\\Users\\Laiba Ahmad\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[1;32mc:\\Users\\Laiba Ahmad\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[1;32mc:\\Users\\Laiba Ahmad\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","Cell \u001b[1;32mIn[42], line 33\u001b[0m, in \u001b[0;36mUTKDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;66;03m# load the data at index and apply transform\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[index]\n\u001b[1;32m---> 33\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;66;03m# load the labels into a list and convert to tensors\u001b[39;00m\n\u001b[0;32m     36\u001b[0m     labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mage_label[index], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgender_label[index], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meth_label[index]))\n","File \u001b[1;32mc:\\Users\\Laiba Ahmad\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n","File \u001b[1;32mc:\\Users\\Laiba Ahmad\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\transforms\\transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[0;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\Laiba Ahmad\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\transforms\\functional.py:154\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pic\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    152\u001b[0m     pic \u001b[38;5;241m=\u001b[39m pic[:, :, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m--> 154\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[0;32m    155\u001b[0m \u001b[38;5;66;03m# backward compatibility\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch\u001b[38;5;241m.\u001b[39mByteTensor):\n","\u001b[1;31mRuntimeError\u001b[0m: Numpy is not available"]}],"source":["\n","import numpy as np\n","\n","# Read in the dataframe\n","dataFrame = pd.read_csv(r'C:\\Users\\Laiba Ahmad\\Downloads\\age_gender.gz', compression='gzip')\n"," \n","# Construct age bins\n","age_bins = [0,10,15,20,25,30,40,50,60,120]\n","age_labels = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n","dataFrame['bins'] = pd.cut(dataFrame.age, bins=age_bins, labels=age_labels)\n","\n","# Split into training and testing\n","train_dataFrame, test_dataFrame = train_test_split(dataFrame, test_size=0.2)\n","\n","# get the number of unique classes for each group\n","class_nums = {'age_num':len(dataFrame['bins'].unique()), 'eth_num':len(dataFrame['ethnicity'].unique()),\n","              'gen_num':len(dataFrame['gender'].unique())}\n","\n","# Define train and test transforms\n","train_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.49,), (0.23,))\n","])\n","\n","test_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.49,), (0.23,))\n","])\n","\n","# Construct the custom pytorch datasets\n","train_set = UTKDataset(train_dataFrame, transform=train_transform)\n","test_set = UTKDataset(test_dataFrame, transform=test_transform)\n","\n","# Load the datasets into dataloaders\n","trainloader = DataLoader(train_set, batch_size=64, shuffle=True)\n","testloader = DataLoader(test_set, batch_size=128, shuffle=False)\n","\n","# Sanity Check\n","for X, y in trainloader:\n","    print(f'Shape of training X: {X.shape}')\n","    print(f'Shape of y: {y.shape}')\n","    break "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":154,"status":"ok","timestamp":1624053999222,"user":{"displayName":"Armin Bazarjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWMh-oi0YJtI-yJdyLDSVztfUualX2xpx_lq-GGA=s64","userId":"09638783858940923330"},"user_tz":420},"id":"KHME6XaiB4RA","outputId":"a410ed61-bd19-484b-d55c-a5c252d4b162"},"outputs":[],"source":["# Configure the device \n","device = 'cuda' if torch.cuda.is_available() else 'cpu' \n","print(device)\n","\n","# Define the list of hyperparameters\n","hyperparameters = {'learning_rate':0.001, 'epochs':30}\n","\n","# Initialize the TridentNN model and put on device\n","model = TridentNN(class_nums['age_num'], class_nums['gen_num'], class_nums['eth_num'])\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":146,"status":"ok","timestamp":1624054001685,"user":{"displayName":"Armin Bazarjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWMh-oi0YJtI-yJdyLDSVztfUualX2xpx_lq-GGA=s64","userId":"09638783858940923330"},"user_tz":420},"id":"M1e1Yf_bE2bt"},"outputs":[],"source":["'''\n","  Functions to load and save a PyTorch model\n","'''\n","def save_checkpoint(state, epoch):\n","  print(\"Saving Checkpoint\")\n","  filename = \"tridentNN_epoch\"+str(epoch)+\".pth.tar\"\n","  torch.save(state,filename)\n","\n","def load_checkpoint(checkpoint):\n","  print(\"Loading Checkpoint\")\n","  model.load_state_dict(checkpoint['state_dict'])\n","  opt.load_state_dict(checkpoint['optimizer'])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":253766,"status":"error","timestamp":1624054575708,"user":{"displayName":"Armin Bazarjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWMh-oi0YJtI-yJdyLDSVztfUualX2xpx_lq-GGA=s64","userId":"09638783858940923330"},"user_tz":420},"id":"FGdpJIvvJZWk","outputId":"87e7214d-35c1-4bec-a921-209981ab7862"},"outputs":[],"source":["'''\n","train the model\n","''' \n","# Load hyperparameters\n","learning_rate = hyperparameters['learning_rate']\n","num_epoch = hyperparameters['epochs']\n","\n","# Define loss functions\n","age_loss = nn.CrossEntropyLoss()\n","gen_loss = nn.CrossEntropyLoss() # TODO : Explore using Binary Cross Entropy Loss?\n","eth_loss = nn.CrossEntropyLoss()\n","\n","# Define optimizer\n","opt = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Train the model\n","for epoch in range(num_epoch):\n","  # Construct tqdm loop to keep track of training\n","  loop = tqdm(enumerate(trainloader), total=len(trainloader), position=0, leave=True)\n","  age_correct, gen_correct, eth_correct, total = 0,0,0,0\n","\n","  # save the model every 10 epochs\n","  if epoch % 10 == 0:\n","    checkpoint = {'state_dict' : model.state_dict(), 'optimizer' : opt.state_dict(), \n","                  'age_loss' : age_loss, 'gen_loss' : gen_loss, 'eth_loss' : eth_loss}\n","    save_checkpoint(checkpoint, epoch)\n","\n","  # Loop through dataLoader\n","  for _, (X,y) in loop:\n","    # Unpack y to get true age, eth, and gen values\n","    # Have to do some special changes to age label to make it compatible with NN output and Loss function\n","    #age, gen, eth = y[:,0].resize_(len(y[:,0]),1).float().to(device), y[:,1].to(device), y[:,2].to(device)\n","    age, gen, eth = y[:,0].to(device), y[:,1].to(device), y[:,2].to(device)\n","    X = X.to(device)\n","    pred = model(X)          # Forward pass\n","    loss = age_loss(pred[0],age) + gen_loss(pred[1],gen) + eth_loss(pred[2],eth)   # Loss calculation\n","\n","    # Backpropagation\n","    opt.zero_grad()          # Zero the gradient\n","    loss.backward()          # Calculate updates\n","\n","    # Gradient Descent\n","    opt.step()               # Apply updates\n","\n","    # Update num correct and total\n","    age_correct += (pred[0].argmax(1) == age).type(torch.float).sum().item()\n","    gen_correct += (pred[1].argmax(1) == gen).type(torch.float).sum().item()\n","    eth_correct += (pred[2].argmax(1) == eth).type(torch.float).sum().item()\n","\n","    total += len(y)\n","\n","    # Update progress bar\n","    loop.set_description(f\"Epoch [{epoch+1}/{num_epoch}]\")\n","    loop.set_postfix(loss = loss.item())\n","\n","  # Update epoch accuracy\n","  gen_acc, eth_acc, age_acc = gen_correct/total, eth_correct/total, age_correct/total\n","\n","  # print out accuracy and loss for epoch\n","  print(f'Epoch : {epoch+1}/{num_epoch},    Age Accuracy : {age_acc*100},    Gender Accuracy : {gen_acc*100},    Ethnicity Accuracy : {eth_acc*100}\\n')"]},{"cell_type":"markdown","metadata":{"id":"F9sxKcPyNLxg"},"source":["I manuall interrupted the training because I wanted everything to have a training accuracy > 90% and I didn't code that part in yet\n","<br> <br>\n","Now I am going to test the model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":859,"status":"ok","timestamp":1624054785585,"user":{"displayName":"Armin Bazarjani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWMh-oi0YJtI-yJdyLDSVztfUualX2xpx_lq-GGA=s64","userId":"09638783858940923330"},"user_tz":420},"id":"lKD70kYxPUvl","outputId":"c5a38afd-98e6-4ba4-f456-eb2dfe0de780"},"outputs":[],"source":["test(testloader, model)"]},{"cell_type":"markdown","metadata":{"id":"WR8_D6ERNWln"},"source":["As you can see the testing accuracy is not that great. My hypothesis is that predicting age is actually a very difficult task because there is so much variation between how people age.\n","<br> <br> \n","Even between different genders and ethnicities there is so much variance. Therefore, we have both inter and intra-variance when it comes to age.\n","<br> <br>\n","Perhaps a better approach would be to feed the outputs of the gender and ethnicity classifier to the age classifier so it can use that information as well. But, that's a project for another day."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from PIL import Image\n","\n","\n","# Define a new dataset class for the new images\n","class NewDataset(Dataset):\n","    def __init__(self, image_paths, transform=None):\n","        self.image_paths = image_paths\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, index):\n","        image_path = self.image_paths[index]\n","        image = Image.open(image_path).convert('RGB')  # Convert to RGB if needed\n","        if self.transform:\n","            image = self.transform(image)\n","        return image\n","\n","# Example image paths\n","image_paths = ['../image1.jpg', '../image4.jpg','../image19.jpg', '../image26.jpg', '../image75.jpg']\n","\n","# Define transformations for the new images\n","new_transform = transforms.Compose([\n","    transforms.Resize((48, 48)),  # Resize to match model input size\n","    transforms.Grayscale(num_output_channels=1),  # Convert images to grayscale\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.49,), (0.23,))\n","])\n","\n","\n","# Create a new dataset for the new images\n","new_dataset = NewDataset(image_paths, transform=new_transform)\n","\n","# Create a DataLoader for the new dataset\n","new_dataloader = DataLoader(new_dataset, batch_size=5, shuffle=False)\n","\n","# Test the model on the new images\n","model.eval()\n","\n","with torch.no_grad():\n","    for images in new_dataloader:\n","        images = images.to(device)\n","        age_preds, gen_preds, eth_preds = model(images)\n","        \n","        # Convert predictions to labels\n","        age_labels = age_preds.argmax(dim=1)\n","        gen_labels = gen_preds.argmax(dim=1)\n","        eth_labels = eth_preds.argmax(dim=1)\n","        \n","        # Print the predictions for each image\n","        for i in range(len(age_labels)):\n","            print(f\"Image {i+1}: Age - {age_labels[i]}, Gender - {gen_labels[i]}, Ethnicity - {eth_labels[i]}\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMwy8EJP0FeZjhJgqMk7Yvj","collapsed_sections":[],"name":"TrainTridentMain.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.2"}},"nbformat":4,"nbformat_minor":0}
